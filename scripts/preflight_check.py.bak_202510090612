# -*- coding: utf-8 -*-
# Preflight (Strict Fix)
# 目標：
#  - 穩健地輸出 freshness 四鍵：prices/chip/dividend/per，皆含 max_date (yyyy-MM-dd)
#  - 只掃當月與前一月分區，避免 I/O 過大
#  - expect_date = (Asia/Taipei 今日 + 1 天)；console 輸出與舊版相容
#  - JSON 結構：{ meta: { expect_date, tz }, freshness: {prices:{max_date},...}, dup_check: {...} }

import os, sys, json, glob, datetime
from typing import Dict, Tuple, List
import pandas as pd

try:
    from zoneinfo import ZoneInfo
except Exception:
    ZoneInfo = None

def tz_today_iso(tz_name: str) -> str:
    tz = ZoneInfo(tz_name) if ZoneInfo else None
    now = datetime.datetime.now(tz) if tz else datetime.datetime.now()
    return now.date().isoformat()

def expect_date_iso(tz_name: str) -> str:
    tz = ZoneInfo(tz_name) if ZoneInfo else None
    now = datetime.datetime.now(tz) if tz else datetime.datetime.now()
    return (now.date() + datetime.timedelta(days=1)).isoformat()

def list_recent_partitions(base: str, n_months: int = 2) -> List[str]:
    """回傳 yyyymm=YYYYMM 目錄（最多 n_months 個，倒序）"""
    if not os.path.isdir(base):
        return []
    yms = []
    for name in os.listdir(base):
        if name.startswith("yyyymm="):
            y = name.split("=")[1]
            if len(y) == 6 and y.isdigit():
                yms.append(y)
    yms = sorted(set(yms))[-n_months:]
    return [os.path.join(base, f"yyyymm={ym}") for ym in yms]

def max_date_in_kind(datahub_root: str, kind: str) -> Tuple[str,int]:
    """掃描 kind（只看當月與前月）回傳 (max_date, files_count)"""
    base = os.path.join(datahub_root, "silver", "alpha", kind)
    parts = list_recent_partitions(base, n_months=2)
    files = []
    for p in parts:
        files.extend(glob.glob(os.path.join(p, "**", "*.parquet"), recursive=True))
    max_d = None
    for f in files:
        try:
            df = pd.read_parquet(f, columns=["date"])
            if df.empty:
                continue
            d = pd.to_datetime(df["date"], errors="coerce")
            dm = d.max()
            if pd.notna(dm):
                v = dm.date().isoformat()
                if (max_d is None) or (v > max_d):
                    max_d = v
        except Exception:
            pass
    return (max_d, len(files))

def main():
    import argparse
    ap = argparse.ArgumentParser()
    ap.add_argument("--rules", required=False, help="(保留參數，未使用)")
    ap.add_argument("--export", default="reports")
    ap.add_argument("--root", default=".")
    args = ap.parse_args()

    root = os.path.abspath(args.root)
    datahub_root = os.path.join(root, "datahub")

    tz = "Asia/Taipei"
    exp = expect_date_iso(tz)
    t0  = (datetime.date.fromisoformat(exp) - datetime.timedelta(days=1)).isoformat()

    kinds = ["prices","chip","dividend","per"]
    kind_to_path = {
        "prices":   os.path.join(datahub_root,"silver","alpha","prices"),
        "chip":     os.path.join(datahub_root,"silver","alpha","chip"),
        "dividend": os.path.join(datahub_root,"silver","alpha","dividend"),
        "per":      os.path.join(datahub_root,"silver","alpha","per"),
    }

    freshness: Dict[str, Dict[str,str]] = {}
    status_lines = []
    for k in kinds:
        mx, files = max_date_in_kind(datahub_root, k)
        freshness[k] = {"max_date": mx}
        ok = (mx is not None) and (mx >= t0)
        stat = "OK" if ok else "FAIL"
        status_lines.append(f"  freshness [{stat}] {kind_to_path[k].replace('/', r'\\\\')} max_date={mx}")

    # dup_check 先固定 0（若有另一套重覆檢查，可在此擴充）
    dup_check = { k: {"bak_count": 0} for k in kinds }

    # 輸出 console（與舊版相容）
    print(f"[Preflight] expect_date={exp} tz={tz}")
    for line in status_lines:
        print(line)
    for k in kinds:
        print(f"  dup_check [OK] {kind_to_path[k].replace('/', r'\\\\')} bak_count=0")

    # 輸出 JSON
    os.makedirs(args.export, exist_ok=True)
    out = {
        "meta": {
            "expect_date": exp,
            "tz": tz,
            "generated_at": datetime.datetime.now().isoformat(timespec="seconds")
        },
        "freshness": freshness,
        "dup_check": dup_check
    }
    with open(os.path.join(args.export, "preflight_report.json"), "w", encoding="utf-8") as fh:
        json.dump(out, fh, ensure_ascii=False, indent=2)

if __name__ == "__main__":
    # stdout UTF-8
    try:
        if hasattr(sys.stdout, "reconfigure"):
            sys.stdout.reconfigure(encoding="utf-8")
    except Exception:
        pass
    main()
