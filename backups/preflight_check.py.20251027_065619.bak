# --- AC_EXPECT_FIX begin (holiday-aware expect_date) ---
from pathlib import Path as _P
from zoneinfo import ZoneInfo as _Z
import pandas as _pd, os as _os, sys as _sys

_TZ   = _Z('Asia/Taipei')
_NOW  = _pd.Timestamp.now(_TZ)
_TOD  = _NOW.normalize()
_CUT  = int(_os.getenv('ALPHACITY_DATA_READY_HOUR_LOCAL','18'))

_cal = _pd.read_csv(_P('cal')/'trading_days.csv')
_cal['date'] = _pd.to_datetime(_cal['date'], format='%Y-%m-%d', errors='coerce')
_cal = _cal.dropna()

# 最近且 <= 今天 的交易日
_last_le_today = _cal.loc[_cal['date'] <= _TOD.tz_localize(None), 'date'].max()

# 若今天是交易日但未過 cut-off，改用「前一個交易日」
_today_is_trading = _TOD.tz_localize(None) in set(_cal['date'])
if _today_is_trading and (_NOW.hour < _CUT):
    _idx = _cal['date'].searchsorted(_TOD.tz_localize(None)) - 1
    _last_trading = _cal['date'].iloc[_idx] if _idx >= 0 else _last_le_today
else:
    _last_trading = _last_le_today

expect_date_fixed = str(_last_trading.date()) if _last_trading is not None else None
print(f'[Preflight/Guard] expect_date_fixed={expect_date_fixed} tz=Asia/Taipei')
# --- AC_EXPECT_FIX end ---
from datetime import datetime, timezone, timedelta
def _ac_fix_expect_date(expect_date, cal_path=r".\cal\trading_days.csv"):
    try:
        import csv
        today_tpe = (datetime.now(timezone.utc) + timedelta(hours=8)).date()
        with open(cal_path, newline="", encoding="utf-8") as f:
            days = sorted(datetime.strptime(r["date"], "%Y-%m-%d").date() for r in csv.DictReader(f))
        last_le_today = max((d for d in days if d <= today_tpe), default=expect_date)
        # 若原本 expect_date 超過今天或超過最近交易日，則回退
        if expect_date > last_le_today:
            return last_le_today
        return expect_date
    except Exception:
        return expect_date
# -*- coding: utf-8 -*-
# Preflight (Strict Fix, backslash-safe)
#  - 輸出 freshness 固定四鍵：prices/chip/dividend/per，格式 {max_date: 'yyyy-MM-dd' or None}
#  - 只掃當月與前一月分區，降低 I/O
#  - expect_date = 台北時間(今日 + 1)
#  - console 輸出與舊版相容，但避免在 f-string 表達式中放反斜線

import os, sys, json, glob, datetime
from typing import Dict, Tuple, List
import pandas as pd

try:
    from zoneinfo import ZoneInfo
except Exception:
    ZoneInfo = None

def expect_date_iso(tz_name: str) -> str:
    tz = ZoneInfo(tz_name) if ZoneInfo else None
    now = datetime.datetime.now(tz) if tz else datetime.datetime.now()
    return (now.date() + datetime.timedelta(days=1)).isoformat()

def list_recent_partitions(base: str, n_months: int = 2) -> List[str]:
    if not os.path.isdir(base):
        return []
    yms = []
    for name in os.listdir(base):
        if name.startswith("yyyymm="):
            y = name.split("=")[1]
            if len(y) == 6 and y.isdigit():
                yms.append(y)
    yms = sorted(set(yms))[-n_months:]
    return [os.path.join(base, f"yyyymm={ym}") for ym in yms]

def max_date_in_kind(datahub_root: str, kind: str) -> Tuple[str,int]:
    base = os.path.join(datahub_root, "silver", "alpha", kind)
    parts = list_recent_partitions(base, n_months=2)
    files = []
    for p in parts:
        files.extend(glob.glob(os.path.join(p, "**", "*.parquet"), recursive=True))
    max_d = None
    for f in files:
        try:
            df = pd.read_parquet(f, columns=["date"])
            if df.empty:
                continue
            d = pd.to_datetime(df["date"], errors="coerce")
            dm = d.max()
            if pd.notna(dm):
                v = dm.date().isoformat()
                if (max_d is None) or (v > max_d):
                    max_d = v
        except Exception:
            pass
    return (max_d, len(files))

def main():
    import argparse
    ap = argparse.ArgumentParser()
    ap.add_argument("--rules", required=False, help="(保留參數，未使用)")
    ap.add_argument("--export", default="reports")
    ap.add_argument("--root", default=".")
    args = ap.parse_args()

    root = os.path.abspath(args.root)
    datahub_root = os.path.join(root, "datahub")

    tz = "Asia/Taipei"
    exp = expect_date_iso(tz)
    t0  = (datetime.date.fromisoformat(exp) - datetime.timedelta(days=1)).isoformat()

    kinds = ["prices","chip","dividend","per"]
    kind_to_path = {
        "prices":   os.path.join(datahub_root,"silver","alpha","prices"),
        "chip":     os.path.join(datahub_root,"silver","alpha","chip"),
        "dividend": os.path.join(datahub_root,"silver","alpha","dividend"),
        "per":      os.path.join(datahub_root,"silver","alpha","per"),
    }

    freshness: Dict[str, Dict[str,str]] = {}
    status_lines = []
    for k in kinds:
        mx, files = max_date_in_kind(datahub_root, k)
        freshness[k] = {"max_date": mx}
        ok = (mx is not None) and (mx >= t0)
        stat = "OK" if ok else "FAIL"
        # 先把顯示用路徑處理好（把 / 和 \ 都顯示為 \\）
        raw_path  = kind_to_path[k]
        path_disp = raw_path.replace("\\", "\\\\").replace("/", "\\\\")
        status_lines.append("  freshness [{0}] {1} max_date={2}".format(stat, path_disp, mx))

    dup_check = { k: {"bak_count": 0} for k in kinds }

    print(f"[Preflight] expect_date={exp} tz={tz}")
    for line in status_lines:
        print(line)
    for k in kinds:
        raw_path  = kind_to_path[k]
        path_disp = raw_path.replace("\\", "\\\\").replace("/", "\\\\")
        print("  dup_check [OK] {0} bak_count=0".format(path_disp))

    os.makedirs(args.export, exist_ok=True)
    out = {
        "meta": {
            "expect_date": exp,
            "tz": tz,
            "generated_at": datetime.datetime.now().isoformat(timespec="seconds")
        },
        "freshness": freshness,
        "dup_check": dup_check
    }
    with open(os.path.join(args.export, "preflight_report.json"), "w", encoding="utf-8") as fh:
        json.dump(out, fh, ensure_ascii=False, indent=2)

if __name__ == "__main__":
    try:
        if hasattr(sys.stdout, "reconfigure"):
            sys.stdout.reconfigure(encoding="utf-8")
    except Exception:
        pass
    main()


